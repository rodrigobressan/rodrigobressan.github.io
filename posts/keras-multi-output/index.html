<!doctype html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Building a multi-output Convolutional Neural Network with Keras" /><meta property="og:locale" content="en" /><meta name="description" content="In this post, we will be exploring the Keras functional API in order to build a multi-output Deep Learning model. We will show how to train a single model that is capable of predicting three distinct outputs. By using the UTK Face dataset, which is composed of over 20 thousand pictures of people in uncontrolled environments, we will predict the age, gender and sex for each record presented in the dataset, reaching an accuracy of 91% for gender and 78% for race. The dataset The UTKFace dataset is a large dataset composed of over 20 thousand face images with their respectivce annotations of age, gender and ethnicity. The images are properly cropped into the face region, but display some variations in pose, illumination, resolution, etc. In order to retrieve the annotations of each record, we need to parse the filenames. Each record is stored in the following format: age_gender_race_date&amp;time.jpg Where: age is an integer from 0 to 116 gender is an integer in which 0 represents male and 1 represents female race is an integer from 0 to 4, denoting white, black, asian, indian and others, respectively date and time, denoting when the picture was taken If you want to know more about this dataset, please check their website. Let’s start by importing some libraries and creating our dictionary to help us on parsing the information from the dataset, along with some other information (dataset location, training split, width and height of the samples). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import numpy as np import pandas as pd import os import glob import pandas as pd import matplotlib.pyplot as plt import seaborn as sns dataset_folder_name = &#39;UTKFace&#39; TRAIN_TEST_SPLIT = 0.7 IM_WIDTH = IM_HEIGHT = 198 dataset_dict = { &#39;race_id&#39;: { 0: &#39;white&#39;, 1: &#39;black&#39;, 2: &#39;asian&#39;, 3: &#39;indian&#39;, 4: &#39;others&#39; }, &#39;gender_id&#39;: { 0: &#39;male&#39;, 1: &#39;female&#39; } } dataset_dict[&#39;gender_alias&#39;] = dict((g, i) for i, g in dataset_dict[&#39;gender_id&#39;].items()) dataset_dict[&#39;race_alias&#39;] = dict((r, i) for i, r in dataset_dict[&#39;race_id&#39;].items()) Let’s also define a function to help us on extracting the data from our dataset. This function will be used to iterate over each file of the UTK dataset and return a Pandas Dataframe containing all the fields (age, gender and sex) of our records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def parse_dataset(dataset_path, ext=&#39;jpg&#39;): &quot;&quot;&quot; Used to extract information about our dataset. It does iterate over all images and return a DataFrame with the data (age, gender and sex) of all files. &quot;&quot;&quot; def parse_info_from_file(path): &quot;&quot;&quot; Parse information from a single file &quot;&quot;&quot; try: filename = os.path.split(path)[1] filename = os.path.splitext(filename)[0] age, gender, race, _ = filename.split(&#39;_&#39;) return int(age), dataset_dict[&#39;gender_id&#39;][int(gender)], dataset_dict[&#39;race_id&#39;][int(race)] except Exception as ex: return None, None, None files = glob.glob(os.path.join(dataset_path, &quot;*.%s&quot; % ext)) records = [] for file in files: info = parse_info_from_file(file) records.append(info) df = pd.DataFrame(records) df[&#39;file&#39;] = files df.columns = [&#39;age&#39;, &#39;gender&#39;, &#39;race&#39;, &#39;file&#39;] df = df.dropna() return df 1 2 df = parse_dataset(dataset_folder_name) df.head()   age gender race file 0 30 male asian UTKFace/30_0_2_20170119183959989.jpg.chip.jpg 1 13 female others UTKFace/13_1_4_20170103200733438.jpg.chip.jpg 2 36 male white UTKFace/36_0_0_20170104204301875.jpg.chip.jpg 3 72 male black UTKFace/72_0_1_20170116205624331.jpg.chip.jpg 4 35 female white UTKFace/35_1_0_20170116201535811.jpg.chip.jpg 5 80 female white UTKFace/80_1_0_20170110182107291.jpg.chip.jpg 6 1 male asian UTKFace/1_0_2_20161219203236876.jpg.chip.jpg 7 25 female indian UTKFace/25_1_3_20170119171956657.jpg.chip.jpg 8 61 male indian UTKFace/61_0_3_20170109141653583.jpg.chip.jpg 9 32 male indian UTKFace/32_0_3_20170119200339548.jpg.chip.jpg Data visualization As an important step to understand not only the distribution of our dataset, but as well the predictions generated by our model, we need to perform some data visualization process on our dataset. We will start by defining a helper function to generate pie plots based on a given Pandas series: 1 2 3 4 5 6 7 8 9 10 11 import plotly.graph_objects as go def plot_distribution(pd_series): labels = pd_series.value_counts().index.tolist() counts = pd_series.value_counts().values.tolist() pie_plot = go.Pie(labels=labels, values=counts, hole=.3) fig = go.Figure(data=[pie_plot]) fig.update_layout(title_text=&#39;Distribution for %s&#39; % pd_series.name) fig.show() Race distribution Let’s start by plotting the race distribution with our predefined plot_distribution method. 1 plot_distribution(df[&#39;race&#39;]) Having a quick glance at this plot, we can see that almost half of the samples are from the white race, so we can expect this group to have a great accuracy. Other races such as black, indian and asian also show a good number of samples, probably leading us to good accuracy numbers as well. The race ‘others’ (hispanics, latinos, etc) on the other side, show a small number of samples, being more likely to have a small accuracy. Gender distribution 1 plot_distribution(df[&#39;gender&#39;]) For both male and female samples, we have quite a good balanced number of records, so we should have a great accuracy for both classes when using our model. Age distribution Let’s also plot how our age feature is distributed over the dataset by using a simple histogram with 20 bins. 1 2 3 4 import plotly.express as px fig = px.histogram(df, x=&quot;age&quot;, nbins=20) fig.update_layout(title_text=&#39;Age distribution&#39;) fig.show() We can also display this same plot in a pie plot. Let’s group the age column into bins and then plot it with a pie chart 1 2 3 4 5 bins = [0, 10, 20, 30, 40, 60, 80, np.inf] names = [&#39;&lt;10&#39;, &#39;10-20&#39;, &#39;20-30&#39;, &#39;30-40&#39;, &#39;40-60&#39;, &#39;60-80&#39;, &#39;80+&#39;] age_binned = pd.cut(df[&#39;age&#39;], bins, labels=names) plot_distribution(age_binned) We can observe that our dataset is mostly composed of individuals which age varies between 20 and 30 years, followed by individuals ranging from 30-40 years and then 40-60 years old. These groups represent around 70% of our dataset, so we can believe that we are going to have a good accuracy on predicting individuals in these ranges. We could also perform some multi-variate analysis on our dataset, but since the scope of this notebook is to demonstrate the usage of a multi-output model with Keras, we won’t be covering it. Data generator In order to input our data to our Keras multi-output model, we will create a helper object to work as a data generator for our dataset. This will be done by generating batches of data, which will be used to feed our multi-output model with both the images and their labels. This step is also done instead of just loading all the dataset into the memory at once, which could lead to an out of memory error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 from keras.utils import to_categorical from PIL import Image class UtkFaceDataGenerator(): &quot;&quot;&quot; Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model. &quot;&quot;&quot; def __init__(self, df): self.df = df def generate_split_indexes(self): p = np.random.permutation(len(self.df)) train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT) train_idx = p[:train_up_to] test_idx = p[train_up_to:] train_up_to = int(train_up_to * TRAIN_TEST_SPLIT) train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:] # converts alias to id self.df[&#39;gender_id&#39;] = self.df[&#39;gender&#39;].map(lambda gender: dataset_dict[&#39;gender_alias&#39;][gender]) self.df[&#39;race_id&#39;] = self.df[&#39;race&#39;].map(lambda race: dataset_dict[&#39;race_alias&#39;][race]) self.max_age = self.df[&#39;age&#39;].max() return train_idx, valid_idx, test_idx def preprocess_image(self, img_path): &quot;&quot;&quot; Used to perform some minor preprocessing on the image before inputting into the network. &quot;&quot;&quot; im = Image.open(img_path) im = im.resize((IM_WIDTH, IM_HEIGHT)) im = np.array(im) / 255.0 return im def generate_images(self, image_idx, is_training, batch_size=16): &quot;&quot;&quot; Used to generate a batch with images when training/testing/validating our Keras model. &quot;&quot;&quot; # arrays to store our batched data images, ages, races, genders = [], [], [], [] while True: for idx in image_idx: person = self.df.iloc[idx] age = person[&#39;age&#39;] race = person[&#39;race_id&#39;] gender = person[&#39;gender_id&#39;] file = person[&#39;file&#39;] im = self.preprocess_image(file) ages.append(age / self.max_age) races.append(to_categorical(race, len(dataset_dict[&#39;race_id&#39;]))) genders.append(to_categorical(gender, len(dataset_dict[&#39;gender_id&#39;]))) images.append(im) # yielding condition if len(images) &gt;= batch_size: yield np.array(images), [np.array(ages), np.array(races), np.array(genders)] images, ages, races, genders = [], [], [], [] if not is_training: break data_generator = UtkFaceDataGenerator(df) train_idx, valid_idx, test_idx = data_generator.generate_split_indexes() Building our model In this step, we will define our multi-output Keras model. Our model will be composed of three major branches, one for each available feature: age, gender and race. The default structure for our convolutional layers is based on a Conv2D layer with a ReLU activation, followed by a BatchNormalization layer, a MaxPooling and then finally a Dropout layer. Each of these layers is then followed by the final Dense layer. This step is repeated for each of the outputs we are trying to predict. These default layers are defined on the make_default_hidden_layers method, which will be reused on building each of the branches of our model. In the code below we will define our class that will be responsible for creating our multi-output model. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 from keras.models import Model from keras.layers.normalization import BatchNormalization from keras.layers.convolutional import Conv2D from keras.layers.convolutional import MaxPooling2D from keras.layers.core import Activation from keras.layers.core import Dropout from keras.layers.core import Lambda from keras.layers.core import Dense from keras.layers import Flatten from keras.layers import Input import tensorflow as tf class UtkMultiOutputModel(): &quot;&quot;&quot; Used to generate our multi-output model. This CNN contains three branches, one for age, other for sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined on the make_default_hidden_layers method. &quot;&quot;&quot; def make_default_hidden_layers(self, inputs): &quot;&quot;&quot; Used to generate a default set of hidden layers. The structure used in this network is defined as: Conv2D -&gt; BatchNormalization -&gt; Pooling -&gt; Dropout &quot;&quot;&quot; x = Conv2D(16, (3, 3), padding=&quot;same&quot;)(inputs) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(3, 3))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) return x def build_race_branch(self, inputs, num_races): &quot;&quot;&quot; Used to build the race branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_races)(x) x = Activation(&quot;softmax&quot;, name=&quot;race_output&quot;)(x) return x def build_gender_branch(self, inputs, num_genders=2): &quot;&quot;&quot; Used to build the gender branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs) x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_genders)(x) x = Activation(&quot;sigmoid&quot;, name=&quot;gender_output&quot;)(x) return x def build_age_branch(self, inputs): &quot;&quot;&quot; Used to build the age branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(1)(x) x = Activation(&quot;linear&quot;, name=&quot;age_output&quot;)(x) return x def assemble_full_model(self, width, height, num_races): &quot;&quot;&quot; Used to assemble our multi-output model CNN. &quot;&quot;&quot; input_shape = (height, width, 3) inputs = Input(shape=input_shape) age_branch = self.build_age_branch(inputs) race_branch = self.build_race_branch(inputs, num_races) gender_branch = self.build_gender_branch(inputs) model = Model(inputs=inputs, outputs = [age_branch, race_branch, gender_branch], name=&quot;face_net&quot;) return model model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict[&#39;race_alias&#39;])) Let’s give a look into our model structure, to have a better understanding of what we are building. We can see from it that we have a single input, that in our case is the image we are feeding the CNN, which does decompose into three separated branches, each with their own Convolutions, followed by their respective Dense layers. Training our model Now it’s time to train our multi-output model, once we have both the data ready to use and the model architecture defined. But before doing this step, we need to compile our model. For this task, we will use a learning rate of 0.0004 and an Adam optimizer, but you can be feel free to try with other hyperparameters. We will also use custom loss weights and a custom loss function for each feature. When building our optimizer, let’s use a decay based on the learning rate divided by the number of epochs, so we will slowly be decreasing our learning rate over the epochs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from keras.optimizers import Adam init_lr = 1e-4 epochs = 100 opt = Adam(lr=init_lr, decay=init_lr / epochs) model.compile(optimizer=opt, loss={ &#39;age_output&#39;: &#39;mse&#39;, &#39;race_output&#39;: &#39;categorical_crossentropy&#39;, &#39;gender_output&#39;: &#39;binary_crossentropy&#39;}, loss_weights={ &#39;age_output&#39;: 4., &#39;race_output&#39;: 1.5, &#39;gender_output&#39;: 0.1}, metrics={ &#39;age_output&#39;: &#39;mae&#39;, &#39;race_output&#39;: &#39;accuracy&#39;, &#39;gender_output&#39;: &#39;accuracy&#39;}) Now let’s train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from keras.callbacks import ModelCheckpoint batch_size = 32 valid_batch_size = 32 train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size) valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size) callbacks = [ ModelCheckpoint(&quot;./model_checkpoint&quot;, monitor=&#39;val_loss&#39;) ] history = model.fit_generator(train_gen, steps_per_epoch=len(train_idx)//batch_size, epochs=epochs, callbacks=callbacks, validation_data=valid_gen, validation_steps=len(valid_idx)//valid_batch_size) Once we have our model trained, let’s give a better look into how our model performed on both training and validation sets over the epochs: Race accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;race_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_race_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for race feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() We can see that by epoch 50 our model stabilizes itself on the validation set, only increasing on the training one, with an accuracy of approximately 80%. Gender accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;gender_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_gender_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for gender feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() Similarly to the race feature, we can see that our model is able to learn most of the patterns to properly predict the gender from a given individual by the 30th epoch, with an accuracy of approximately 90%. Age Mean Absolute Error 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 plt.clf() fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;age_output_mean_absolute_error&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_age_output_mean_absolute_error&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Mean Absolute Error for age feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Mean Absolute Error&#39;) fig.show() In the task of predicting the age feature, we can see that our model takes around 60 epochs to properly stabilize its learning process, with a mean absolute error of 0.09. Overall loss 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;loss&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_loss&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Overall loss&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Loss&#39;) fig.show() We can notice that by the epoch 50 our model starts to stabilize with a loss value of approximately 1.4. There is also a peak in the loss curve which does appear in the Mean Absolute Error for the age feature, which could explain the influence on the learning of the age feature on the overall loss. Evaluating our model on the test set In order to assess how our model performs on the test set, let’s use our UTK data generator class, but this time using the test indexes. We will then call the predict_generator method from our trained model, which will output our the predictions for the test set. 1 2 3 4 test_batch_size = 128 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) age_pred, race_pred, gender_pred = model.predict_generator(test_generator, steps=len(test_idx)//test_batch_size) Let’s iterate one more time over all our test samples, in order to have their labels into a single list. We will also extract the arg max of each record, in order to retrieve the top predictions and ground truths. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) samples = 0 images, age_true, race_true, gender_true = [], [], [], [] for test_batch in test_generator: image = test_batch[0] labels = test_batch[1] images.extend(image) age_true.extend(labels[0]) race_true.extend(labels[1]) gender_true.extend(labels[2]) age_true = np.array(age_true) race_true = np.array(race_true) gender_true = np.array(gender_true) race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1) race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1) age_true = age_true * data_generator.max_age age_pred = age_pred * data_generator.max_age And finally, let’s print the classification reports for each feature on the test set. 1 2 3 4 from sklearn.metrics import classification_report cr_race = classification_report(race_true, race_pred, target_names=dataset_dict[&#39;race_alias&#39;].keys()) print(cr_race) 1 2 3 4 5 6 7 8 9 10 11 precision recall f1-score support white 0.80 0.91 0.85 2994 black 0.86 0.82 0.84 1327 asian 0.86 0.79 0.83 1046 indian 0.74 0.74 0.74 1171 others 0.38 0.19 0.25 502 accuracy 0.80 7040 macro avg 0.73 0.69 0.70 7040 weighted avg 0.78 0.80 0.78 7040 From the report above, we can see that our model is really good at predicting asian and black individuals, with a precision of 0.86, followed by white people with 0.80 and indian with 0.74. The race ‘others’ shows a precision of only 0.38, but we need to take into consideration that this group is composed of different races and ethnicities along with a small number of samples, when compared to the other groups. The weighted accuracy for this classification task is 78%, showing that our classifier was able to properly learn patterns to distinguish different types of races. 1 2 cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict[&#39;gender_alias&#39;].keys()) print(cr_gender) 1 2 3 4 5 6 7 8 precision recall f1-score support male 0.94 0.87 0.91 3735 female 0.87 0.94 0.90 3305 accuracy 0.90 7040 macro avg 0.90 0.91 0.90 7040 weighted avg 0.91 0.90 0.90 7040 From this report, we can notice that our model is really good at predicting the gender of a given individual, with a weighted accuracy of 91% for this task. 1 2 3 from sklearn.metrics import r2_score print(&#39;R2 score for age: &#39;, r2_score(age_true, age_pred)) R2 score for age: 0.5823979466456328 Example of predictions Below we will plot some examples of the performed predictions generated by our model. We can clearly see that our model is really good at predicting gender, race and age, with some minor mistakes for the age feature. References UTK Face Dataset: http://aicip.eecs.utk.edu/wiki/UTKFace Keras Multi-output documentation: https://keras.io/getting-started/functional-api-guide/ SanjayaSubedi post on multi-output model: https://sanjayasubedi.com.np/deeplearning/multioutput-keras/ PyImageSearch post on FashionNet: https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/ Plotly: https://plot.ly/" /><meta property="og:description" content="In this post, we will be exploring the Keras functional API in order to build a multi-output Deep Learning model. We will show how to train a single model that is capable of predicting three distinct outputs. By using the UTK Face dataset, which is composed of over 20 thousand pictures of people in uncontrolled environments, we will predict the age, gender and sex for each record presented in the dataset, reaching an accuracy of 91% for gender and 78% for race. The dataset The UTKFace dataset is a large dataset composed of over 20 thousand face images with their respectivce annotations of age, gender and ethnicity. The images are properly cropped into the face region, but display some variations in pose, illumination, resolution, etc. In order to retrieve the annotations of each record, we need to parse the filenames. Each record is stored in the following format: age_gender_race_date&amp;time.jpg Where: age is an integer from 0 to 116 gender is an integer in which 0 represents male and 1 represents female race is an integer from 0 to 4, denoting white, black, asian, indian and others, respectively date and time, denoting when the picture was taken If you want to know more about this dataset, please check their website. Let’s start by importing some libraries and creating our dictionary to help us on parsing the information from the dataset, along with some other information (dataset location, training split, width and height of the samples). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import numpy as np import pandas as pd import os import glob import pandas as pd import matplotlib.pyplot as plt import seaborn as sns dataset_folder_name = &#39;UTKFace&#39; TRAIN_TEST_SPLIT = 0.7 IM_WIDTH = IM_HEIGHT = 198 dataset_dict = { &#39;race_id&#39;: { 0: &#39;white&#39;, 1: &#39;black&#39;, 2: &#39;asian&#39;, 3: &#39;indian&#39;, 4: &#39;others&#39; }, &#39;gender_id&#39;: { 0: &#39;male&#39;, 1: &#39;female&#39; } } dataset_dict[&#39;gender_alias&#39;] = dict((g, i) for i, g in dataset_dict[&#39;gender_id&#39;].items()) dataset_dict[&#39;race_alias&#39;] = dict((r, i) for i, r in dataset_dict[&#39;race_id&#39;].items()) Let’s also define a function to help us on extracting the data from our dataset. This function will be used to iterate over each file of the UTK dataset and return a Pandas Dataframe containing all the fields (age, gender and sex) of our records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def parse_dataset(dataset_path, ext=&#39;jpg&#39;): &quot;&quot;&quot; Used to extract information about our dataset. It does iterate over all images and return a DataFrame with the data (age, gender and sex) of all files. &quot;&quot;&quot; def parse_info_from_file(path): &quot;&quot;&quot; Parse information from a single file &quot;&quot;&quot; try: filename = os.path.split(path)[1] filename = os.path.splitext(filename)[0] age, gender, race, _ = filename.split(&#39;_&#39;) return int(age), dataset_dict[&#39;gender_id&#39;][int(gender)], dataset_dict[&#39;race_id&#39;][int(race)] except Exception as ex: return None, None, None files = glob.glob(os.path.join(dataset_path, &quot;*.%s&quot; % ext)) records = [] for file in files: info = parse_info_from_file(file) records.append(info) df = pd.DataFrame(records) df[&#39;file&#39;] = files df.columns = [&#39;age&#39;, &#39;gender&#39;, &#39;race&#39;, &#39;file&#39;] df = df.dropna() return df 1 2 df = parse_dataset(dataset_folder_name) df.head()   age gender race file 0 30 male asian UTKFace/30_0_2_20170119183959989.jpg.chip.jpg 1 13 female others UTKFace/13_1_4_20170103200733438.jpg.chip.jpg 2 36 male white UTKFace/36_0_0_20170104204301875.jpg.chip.jpg 3 72 male black UTKFace/72_0_1_20170116205624331.jpg.chip.jpg 4 35 female white UTKFace/35_1_0_20170116201535811.jpg.chip.jpg 5 80 female white UTKFace/80_1_0_20170110182107291.jpg.chip.jpg 6 1 male asian UTKFace/1_0_2_20161219203236876.jpg.chip.jpg 7 25 female indian UTKFace/25_1_3_20170119171956657.jpg.chip.jpg 8 61 male indian UTKFace/61_0_3_20170109141653583.jpg.chip.jpg 9 32 male indian UTKFace/32_0_3_20170119200339548.jpg.chip.jpg Data visualization As an important step to understand not only the distribution of our dataset, but as well the predictions generated by our model, we need to perform some data visualization process on our dataset. We will start by defining a helper function to generate pie plots based on a given Pandas series: 1 2 3 4 5 6 7 8 9 10 11 import plotly.graph_objects as go def plot_distribution(pd_series): labels = pd_series.value_counts().index.tolist() counts = pd_series.value_counts().values.tolist() pie_plot = go.Pie(labels=labels, values=counts, hole=.3) fig = go.Figure(data=[pie_plot]) fig.update_layout(title_text=&#39;Distribution for %s&#39; % pd_series.name) fig.show() Race distribution Let’s start by plotting the race distribution with our predefined plot_distribution method. 1 plot_distribution(df[&#39;race&#39;]) Having a quick glance at this plot, we can see that almost half of the samples are from the white race, so we can expect this group to have a great accuracy. Other races such as black, indian and asian also show a good number of samples, probably leading us to good accuracy numbers as well. The race ‘others’ (hispanics, latinos, etc) on the other side, show a small number of samples, being more likely to have a small accuracy. Gender distribution 1 plot_distribution(df[&#39;gender&#39;]) For both male and female samples, we have quite a good balanced number of records, so we should have a great accuracy for both classes when using our model. Age distribution Let’s also plot how our age feature is distributed over the dataset by using a simple histogram with 20 bins. 1 2 3 4 import plotly.express as px fig = px.histogram(df, x=&quot;age&quot;, nbins=20) fig.update_layout(title_text=&#39;Age distribution&#39;) fig.show() We can also display this same plot in a pie plot. Let’s group the age column into bins and then plot it with a pie chart 1 2 3 4 5 bins = [0, 10, 20, 30, 40, 60, 80, np.inf] names = [&#39;&lt;10&#39;, &#39;10-20&#39;, &#39;20-30&#39;, &#39;30-40&#39;, &#39;40-60&#39;, &#39;60-80&#39;, &#39;80+&#39;] age_binned = pd.cut(df[&#39;age&#39;], bins, labels=names) plot_distribution(age_binned) We can observe that our dataset is mostly composed of individuals which age varies between 20 and 30 years, followed by individuals ranging from 30-40 years and then 40-60 years old. These groups represent around 70% of our dataset, so we can believe that we are going to have a good accuracy on predicting individuals in these ranges. We could also perform some multi-variate analysis on our dataset, but since the scope of this notebook is to demonstrate the usage of a multi-output model with Keras, we won’t be covering it. Data generator In order to input our data to our Keras multi-output model, we will create a helper object to work as a data generator for our dataset. This will be done by generating batches of data, which will be used to feed our multi-output model with both the images and their labels. This step is also done instead of just loading all the dataset into the memory at once, which could lead to an out of memory error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 from keras.utils import to_categorical from PIL import Image class UtkFaceDataGenerator(): &quot;&quot;&quot; Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model. &quot;&quot;&quot; def __init__(self, df): self.df = df def generate_split_indexes(self): p = np.random.permutation(len(self.df)) train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT) train_idx = p[:train_up_to] test_idx = p[train_up_to:] train_up_to = int(train_up_to * TRAIN_TEST_SPLIT) train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:] # converts alias to id self.df[&#39;gender_id&#39;] = self.df[&#39;gender&#39;].map(lambda gender: dataset_dict[&#39;gender_alias&#39;][gender]) self.df[&#39;race_id&#39;] = self.df[&#39;race&#39;].map(lambda race: dataset_dict[&#39;race_alias&#39;][race]) self.max_age = self.df[&#39;age&#39;].max() return train_idx, valid_idx, test_idx def preprocess_image(self, img_path): &quot;&quot;&quot; Used to perform some minor preprocessing on the image before inputting into the network. &quot;&quot;&quot; im = Image.open(img_path) im = im.resize((IM_WIDTH, IM_HEIGHT)) im = np.array(im) / 255.0 return im def generate_images(self, image_idx, is_training, batch_size=16): &quot;&quot;&quot; Used to generate a batch with images when training/testing/validating our Keras model. &quot;&quot;&quot; # arrays to store our batched data images, ages, races, genders = [], [], [], [] while True: for idx in image_idx: person = self.df.iloc[idx] age = person[&#39;age&#39;] race = person[&#39;race_id&#39;] gender = person[&#39;gender_id&#39;] file = person[&#39;file&#39;] im = self.preprocess_image(file) ages.append(age / self.max_age) races.append(to_categorical(race, len(dataset_dict[&#39;race_id&#39;]))) genders.append(to_categorical(gender, len(dataset_dict[&#39;gender_id&#39;]))) images.append(im) # yielding condition if len(images) &gt;= batch_size: yield np.array(images), [np.array(ages), np.array(races), np.array(genders)] images, ages, races, genders = [], [], [], [] if not is_training: break data_generator = UtkFaceDataGenerator(df) train_idx, valid_idx, test_idx = data_generator.generate_split_indexes() Building our model In this step, we will define our multi-output Keras model. Our model will be composed of three major branches, one for each available feature: age, gender and race. The default structure for our convolutional layers is based on a Conv2D layer with a ReLU activation, followed by a BatchNormalization layer, a MaxPooling and then finally a Dropout layer. Each of these layers is then followed by the final Dense layer. This step is repeated for each of the outputs we are trying to predict. These default layers are defined on the make_default_hidden_layers method, which will be reused on building each of the branches of our model. In the code below we will define our class that will be responsible for creating our multi-output model. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 from keras.models import Model from keras.layers.normalization import BatchNormalization from keras.layers.convolutional import Conv2D from keras.layers.convolutional import MaxPooling2D from keras.layers.core import Activation from keras.layers.core import Dropout from keras.layers.core import Lambda from keras.layers.core import Dense from keras.layers import Flatten from keras.layers import Input import tensorflow as tf class UtkMultiOutputModel(): &quot;&quot;&quot; Used to generate our multi-output model. This CNN contains three branches, one for age, other for sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined on the make_default_hidden_layers method. &quot;&quot;&quot; def make_default_hidden_layers(self, inputs): &quot;&quot;&quot; Used to generate a default set of hidden layers. The structure used in this network is defined as: Conv2D -&gt; BatchNormalization -&gt; Pooling -&gt; Dropout &quot;&quot;&quot; x = Conv2D(16, (3, 3), padding=&quot;same&quot;)(inputs) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(3, 3))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) return x def build_race_branch(self, inputs, num_races): &quot;&quot;&quot; Used to build the race branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_races)(x) x = Activation(&quot;softmax&quot;, name=&quot;race_output&quot;)(x) return x def build_gender_branch(self, inputs, num_genders=2): &quot;&quot;&quot; Used to build the gender branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs) x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_genders)(x) x = Activation(&quot;sigmoid&quot;, name=&quot;gender_output&quot;)(x) return x def build_age_branch(self, inputs): &quot;&quot;&quot; Used to build the age branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(1)(x) x = Activation(&quot;linear&quot;, name=&quot;age_output&quot;)(x) return x def assemble_full_model(self, width, height, num_races): &quot;&quot;&quot; Used to assemble our multi-output model CNN. &quot;&quot;&quot; input_shape = (height, width, 3) inputs = Input(shape=input_shape) age_branch = self.build_age_branch(inputs) race_branch = self.build_race_branch(inputs, num_races) gender_branch = self.build_gender_branch(inputs) model = Model(inputs=inputs, outputs = [age_branch, race_branch, gender_branch], name=&quot;face_net&quot;) return model model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict[&#39;race_alias&#39;])) Let’s give a look into our model structure, to have a better understanding of what we are building. We can see from it that we have a single input, that in our case is the image we are feeding the CNN, which does decompose into three separated branches, each with their own Convolutions, followed by their respective Dense layers. Training our model Now it’s time to train our multi-output model, once we have both the data ready to use and the model architecture defined. But before doing this step, we need to compile our model. For this task, we will use a learning rate of 0.0004 and an Adam optimizer, but you can be feel free to try with other hyperparameters. We will also use custom loss weights and a custom loss function for each feature. When building our optimizer, let’s use a decay based on the learning rate divided by the number of epochs, so we will slowly be decreasing our learning rate over the epochs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from keras.optimizers import Adam init_lr = 1e-4 epochs = 100 opt = Adam(lr=init_lr, decay=init_lr / epochs) model.compile(optimizer=opt, loss={ &#39;age_output&#39;: &#39;mse&#39;, &#39;race_output&#39;: &#39;categorical_crossentropy&#39;, &#39;gender_output&#39;: &#39;binary_crossentropy&#39;}, loss_weights={ &#39;age_output&#39;: 4., &#39;race_output&#39;: 1.5, &#39;gender_output&#39;: 0.1}, metrics={ &#39;age_output&#39;: &#39;mae&#39;, &#39;race_output&#39;: &#39;accuracy&#39;, &#39;gender_output&#39;: &#39;accuracy&#39;}) Now let’s train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from keras.callbacks import ModelCheckpoint batch_size = 32 valid_batch_size = 32 train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size) valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size) callbacks = [ ModelCheckpoint(&quot;./model_checkpoint&quot;, monitor=&#39;val_loss&#39;) ] history = model.fit_generator(train_gen, steps_per_epoch=len(train_idx)//batch_size, epochs=epochs, callbacks=callbacks, validation_data=valid_gen, validation_steps=len(valid_idx)//valid_batch_size) Once we have our model trained, let’s give a better look into how our model performed on both training and validation sets over the epochs: Race accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;race_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_race_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for race feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() We can see that by epoch 50 our model stabilizes itself on the validation set, only increasing on the training one, with an accuracy of approximately 80%. Gender accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;gender_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_gender_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for gender feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() Similarly to the race feature, we can see that our model is able to learn most of the patterns to properly predict the gender from a given individual by the 30th epoch, with an accuracy of approximately 90%. Age Mean Absolute Error 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 plt.clf() fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;age_output_mean_absolute_error&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_age_output_mean_absolute_error&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Mean Absolute Error for age feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Mean Absolute Error&#39;) fig.show() In the task of predicting the age feature, we can see that our model takes around 60 epochs to properly stabilize its learning process, with a mean absolute error of 0.09. Overall loss 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;loss&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_loss&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Overall loss&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Loss&#39;) fig.show() We can notice that by the epoch 50 our model starts to stabilize with a loss value of approximately 1.4. There is also a peak in the loss curve which does appear in the Mean Absolute Error for the age feature, which could explain the influence on the learning of the age feature on the overall loss. Evaluating our model on the test set In order to assess how our model performs on the test set, let’s use our UTK data generator class, but this time using the test indexes. We will then call the predict_generator method from our trained model, which will output our the predictions for the test set. 1 2 3 4 test_batch_size = 128 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) age_pred, race_pred, gender_pred = model.predict_generator(test_generator, steps=len(test_idx)//test_batch_size) Let’s iterate one more time over all our test samples, in order to have their labels into a single list. We will also extract the arg max of each record, in order to retrieve the top predictions and ground truths. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) samples = 0 images, age_true, race_true, gender_true = [], [], [], [] for test_batch in test_generator: image = test_batch[0] labels = test_batch[1] images.extend(image) age_true.extend(labels[0]) race_true.extend(labels[1]) gender_true.extend(labels[2]) age_true = np.array(age_true) race_true = np.array(race_true) gender_true = np.array(gender_true) race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1) race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1) age_true = age_true * data_generator.max_age age_pred = age_pred * data_generator.max_age And finally, let’s print the classification reports for each feature on the test set. 1 2 3 4 from sklearn.metrics import classification_report cr_race = classification_report(race_true, race_pred, target_names=dataset_dict[&#39;race_alias&#39;].keys()) print(cr_race) 1 2 3 4 5 6 7 8 9 10 11 precision recall f1-score support white 0.80 0.91 0.85 2994 black 0.86 0.82 0.84 1327 asian 0.86 0.79 0.83 1046 indian 0.74 0.74 0.74 1171 others 0.38 0.19 0.25 502 accuracy 0.80 7040 macro avg 0.73 0.69 0.70 7040 weighted avg 0.78 0.80 0.78 7040 From the report above, we can see that our model is really good at predicting asian and black individuals, with a precision of 0.86, followed by white people with 0.80 and indian with 0.74. The race ‘others’ shows a precision of only 0.38, but we need to take into consideration that this group is composed of different races and ethnicities along with a small number of samples, when compared to the other groups. The weighted accuracy for this classification task is 78%, showing that our classifier was able to properly learn patterns to distinguish different types of races. 1 2 cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict[&#39;gender_alias&#39;].keys()) print(cr_gender) 1 2 3 4 5 6 7 8 precision recall f1-score support male 0.94 0.87 0.91 3735 female 0.87 0.94 0.90 3305 accuracy 0.90 7040 macro avg 0.90 0.91 0.90 7040 weighted avg 0.91 0.90 0.90 7040 From this report, we can notice that our model is really good at predicting the gender of a given individual, with a weighted accuracy of 91% for this task. 1 2 3 from sklearn.metrics import r2_score print(&#39;R2 score for age: &#39;, r2_score(age_true, age_pred)) R2 score for age: 0.5823979466456328 Example of predictions Below we will plot some examples of the performed predictions generated by our model. We can clearly see that our model is really good at predicting gender, race and age, with some minor mistakes for the age feature. References UTK Face Dataset: http://aicip.eecs.utk.edu/wiki/UTKFace Keras Multi-output documentation: https://keras.io/getting-started/functional-api-guide/ SanjayaSubedi post on multi-output model: https://sanjayasubedi.com.np/deeplearning/multioutput-keras/ PyImageSearch post on FashionNet: https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/ Plotly: https://plot.ly/" /><link rel="canonical" href="https://bressan.xyz/posts/keras-multi-output/" /><meta property="og:url" content="https://bressan.xyz/posts/keras-multi-output/" /><meta property="og:site_name" content="Rodrigo Bressan" /><meta property="og:image" content="https://bressan.xyz/assets/img/posts/04-multi-output/banner.jpeg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-03-15T15:00:00+01:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://bressan.xyz/assets/img/posts/04-multi-output/banner.jpeg" /><meta property="twitter:title" content="Building a multi-output Convolutional Neural Network with Keras" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-03-15T15:00:00+01:00","datePublished":"2022-03-15T15:00:00+01:00","description":"In this post, we will be exploring the Keras functional API in order to build a multi-output Deep Learning model. We will show how to train a single model that is capable of predicting three distinct outputs. By using the UTK Face dataset, which is composed of over 20 thousand pictures of people in uncontrolled environments, we will predict the age, gender and sex for each record presented in the dataset, reaching an accuracy of 91% for gender and 78% for race. The dataset The UTKFace dataset is a large dataset composed of over 20 thousand face images with their respectivce annotations of age, gender and ethnicity. The images are properly cropped into the face region, but display some variations in pose, illumination, resolution, etc. In order to retrieve the annotations of each record, we need to parse the filenames. Each record is stored in the following format: age_gender_race_date&amp;time.jpg Where: age is an integer from 0 to 116 gender is an integer in which 0 represents male and 1 represents female race is an integer from 0 to 4, denoting white, black, asian, indian and others, respectively date and time, denoting when the picture was taken If you want to know more about this dataset, please check their website. Let’s start by importing some libraries and creating our dictionary to help us on parsing the information from the dataset, along with some other information (dataset location, training split, width and height of the samples). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import numpy as np import pandas as pd import os import glob import pandas as pd import matplotlib.pyplot as plt import seaborn as sns dataset_folder_name = &#39;UTKFace&#39; TRAIN_TEST_SPLIT = 0.7 IM_WIDTH = IM_HEIGHT = 198 dataset_dict = { &#39;race_id&#39;: { 0: &#39;white&#39;, 1: &#39;black&#39;, 2: &#39;asian&#39;, 3: &#39;indian&#39;, 4: &#39;others&#39; }, &#39;gender_id&#39;: { 0: &#39;male&#39;, 1: &#39;female&#39; } } dataset_dict[&#39;gender_alias&#39;] = dict((g, i) for i, g in dataset_dict[&#39;gender_id&#39;].items()) dataset_dict[&#39;race_alias&#39;] = dict((r, i) for i, r in dataset_dict[&#39;race_id&#39;].items()) Let’s also define a function to help us on extracting the data from our dataset. This function will be used to iterate over each file of the UTK dataset and return a Pandas Dataframe containing all the fields (age, gender and sex) of our records. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def parse_dataset(dataset_path, ext=&#39;jpg&#39;): &quot;&quot;&quot; Used to extract information about our dataset. It does iterate over all images and return a DataFrame with the data (age, gender and sex) of all files. &quot;&quot;&quot; def parse_info_from_file(path): &quot;&quot;&quot; Parse information from a single file &quot;&quot;&quot; try: filename = os.path.split(path)[1] filename = os.path.splitext(filename)[0] age, gender, race, _ = filename.split(&#39;_&#39;) return int(age), dataset_dict[&#39;gender_id&#39;][int(gender)], dataset_dict[&#39;race_id&#39;][int(race)] except Exception as ex: return None, None, None files = glob.glob(os.path.join(dataset_path, &quot;*.%s&quot; % ext)) records = [] for file in files: info = parse_info_from_file(file) records.append(info) df = pd.DataFrame(records) df[&#39;file&#39;] = files df.columns = [&#39;age&#39;, &#39;gender&#39;, &#39;race&#39;, &#39;file&#39;] df = df.dropna() return df 1 2 df = parse_dataset(dataset_folder_name) df.head()   age gender race file 0 30 male asian UTKFace/30_0_2_20170119183959989.jpg.chip.jpg 1 13 female others UTKFace/13_1_4_20170103200733438.jpg.chip.jpg 2 36 male white UTKFace/36_0_0_20170104204301875.jpg.chip.jpg 3 72 male black UTKFace/72_0_1_20170116205624331.jpg.chip.jpg 4 35 female white UTKFace/35_1_0_20170116201535811.jpg.chip.jpg 5 80 female white UTKFace/80_1_0_20170110182107291.jpg.chip.jpg 6 1 male asian UTKFace/1_0_2_20161219203236876.jpg.chip.jpg 7 25 female indian UTKFace/25_1_3_20170119171956657.jpg.chip.jpg 8 61 male indian UTKFace/61_0_3_20170109141653583.jpg.chip.jpg 9 32 male indian UTKFace/32_0_3_20170119200339548.jpg.chip.jpg Data visualization As an important step to understand not only the distribution of our dataset, but as well the predictions generated by our model, we need to perform some data visualization process on our dataset. We will start by defining a helper function to generate pie plots based on a given Pandas series: 1 2 3 4 5 6 7 8 9 10 11 import plotly.graph_objects as go def plot_distribution(pd_series): labels = pd_series.value_counts().index.tolist() counts = pd_series.value_counts().values.tolist() pie_plot = go.Pie(labels=labels, values=counts, hole=.3) fig = go.Figure(data=[pie_plot]) fig.update_layout(title_text=&#39;Distribution for %s&#39; % pd_series.name) fig.show() Race distribution Let’s start by plotting the race distribution with our predefined plot_distribution method. 1 plot_distribution(df[&#39;race&#39;]) Having a quick glance at this plot, we can see that almost half of the samples are from the white race, so we can expect this group to have a great accuracy. Other races such as black, indian and asian also show a good number of samples, probably leading us to good accuracy numbers as well. The race ‘others’ (hispanics, latinos, etc) on the other side, show a small number of samples, being more likely to have a small accuracy. Gender distribution 1 plot_distribution(df[&#39;gender&#39;]) For both male and female samples, we have quite a good balanced number of records, so we should have a great accuracy for both classes when using our model. Age distribution Let’s also plot how our age feature is distributed over the dataset by using a simple histogram with 20 bins. 1 2 3 4 import plotly.express as px fig = px.histogram(df, x=&quot;age&quot;, nbins=20) fig.update_layout(title_text=&#39;Age distribution&#39;) fig.show() We can also display this same plot in a pie plot. Let’s group the age column into bins and then plot it with a pie chart 1 2 3 4 5 bins = [0, 10, 20, 30, 40, 60, 80, np.inf] names = [&#39;&lt;10&#39;, &#39;10-20&#39;, &#39;20-30&#39;, &#39;30-40&#39;, &#39;40-60&#39;, &#39;60-80&#39;, &#39;80+&#39;] age_binned = pd.cut(df[&#39;age&#39;], bins, labels=names) plot_distribution(age_binned) We can observe that our dataset is mostly composed of individuals which age varies between 20 and 30 years, followed by individuals ranging from 30-40 years and then 40-60 years old. These groups represent around 70% of our dataset, so we can believe that we are going to have a good accuracy on predicting individuals in these ranges. We could also perform some multi-variate analysis on our dataset, but since the scope of this notebook is to demonstrate the usage of a multi-output model with Keras, we won’t be covering it. Data generator In order to input our data to our Keras multi-output model, we will create a helper object to work as a data generator for our dataset. This will be done by generating batches of data, which will be used to feed our multi-output model with both the images and their labels. This step is also done instead of just loading all the dataset into the memory at once, which could lead to an out of memory error. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 from keras.utils import to_categorical from PIL import Image class UtkFaceDataGenerator(): &quot;&quot;&quot; Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model. &quot;&quot;&quot; def __init__(self, df): self.df = df def generate_split_indexes(self): p = np.random.permutation(len(self.df)) train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT) train_idx = p[:train_up_to] test_idx = p[train_up_to:] train_up_to = int(train_up_to * TRAIN_TEST_SPLIT) train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:] # converts alias to id self.df[&#39;gender_id&#39;] = self.df[&#39;gender&#39;].map(lambda gender: dataset_dict[&#39;gender_alias&#39;][gender]) self.df[&#39;race_id&#39;] = self.df[&#39;race&#39;].map(lambda race: dataset_dict[&#39;race_alias&#39;][race]) self.max_age = self.df[&#39;age&#39;].max() return train_idx, valid_idx, test_idx def preprocess_image(self, img_path): &quot;&quot;&quot; Used to perform some minor preprocessing on the image before inputting into the network. &quot;&quot;&quot; im = Image.open(img_path) im = im.resize((IM_WIDTH, IM_HEIGHT)) im = np.array(im) / 255.0 return im def generate_images(self, image_idx, is_training, batch_size=16): &quot;&quot;&quot; Used to generate a batch with images when training/testing/validating our Keras model. &quot;&quot;&quot; # arrays to store our batched data images, ages, races, genders = [], [], [], [] while True: for idx in image_idx: person = self.df.iloc[idx] age = person[&#39;age&#39;] race = person[&#39;race_id&#39;] gender = person[&#39;gender_id&#39;] file = person[&#39;file&#39;] im = self.preprocess_image(file) ages.append(age / self.max_age) races.append(to_categorical(race, len(dataset_dict[&#39;race_id&#39;]))) genders.append(to_categorical(gender, len(dataset_dict[&#39;gender_id&#39;]))) images.append(im) # yielding condition if len(images) &gt;= batch_size: yield np.array(images), [np.array(ages), np.array(races), np.array(genders)] images, ages, races, genders = [], [], [], [] if not is_training: break data_generator = UtkFaceDataGenerator(df) train_idx, valid_idx, test_idx = data_generator.generate_split_indexes() Building our model In this step, we will define our multi-output Keras model. Our model will be composed of three major branches, one for each available feature: age, gender and race. The default structure for our convolutional layers is based on a Conv2D layer with a ReLU activation, followed by a BatchNormalization layer, a MaxPooling and then finally a Dropout layer. Each of these layers is then followed by the final Dense layer. This step is repeated for each of the outputs we are trying to predict. These default layers are defined on the make_default_hidden_layers method, which will be reused on building each of the branches of our model. In the code below we will define our class that will be responsible for creating our multi-output model. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 from keras.models import Model from keras.layers.normalization import BatchNormalization from keras.layers.convolutional import Conv2D from keras.layers.convolutional import MaxPooling2D from keras.layers.core import Activation from keras.layers.core import Dropout from keras.layers.core import Lambda from keras.layers.core import Dense from keras.layers import Flatten from keras.layers import Input import tensorflow as tf class UtkMultiOutputModel(): &quot;&quot;&quot; Used to generate our multi-output model. This CNN contains three branches, one for age, other for sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined on the make_default_hidden_layers method. &quot;&quot;&quot; def make_default_hidden_layers(self, inputs): &quot;&quot;&quot; Used to generate a default set of hidden layers. The structure used in this network is defined as: Conv2D -&gt; BatchNormalization -&gt; Pooling -&gt; Dropout &quot;&quot;&quot; x = Conv2D(16, (3, 3), padding=&quot;same&quot;)(inputs) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(3, 3))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) x = Conv2D(32, (3, 3), padding=&quot;same&quot;)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization(axis=-1)(x) x = MaxPooling2D(pool_size=(2, 2))(x) x = Dropout(0.25)(x) return x def build_race_branch(self, inputs, num_races): &quot;&quot;&quot; Used to build the race branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_races)(x) x = Activation(&quot;softmax&quot;, name=&quot;race_output&quot;)(x) return x def build_gender_branch(self, inputs, num_genders=2): &quot;&quot;&quot; Used to build the gender branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs) x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(num_genders)(x) x = Activation(&quot;sigmoid&quot;, name=&quot;gender_output&quot;)(x) return x def build_age_branch(self, inputs): &quot;&quot;&quot; Used to build the age branch of our face recognition network. This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, followed by the Dense output layer. &quot;&quot;&quot; x = self.make_default_hidden_layers(inputs) x = Flatten()(x) x = Dense(128)(x) x = Activation(&quot;relu&quot;)(x) x = BatchNormalization()(x) x = Dropout(0.5)(x) x = Dense(1)(x) x = Activation(&quot;linear&quot;, name=&quot;age_output&quot;)(x) return x def assemble_full_model(self, width, height, num_races): &quot;&quot;&quot; Used to assemble our multi-output model CNN. &quot;&quot;&quot; input_shape = (height, width, 3) inputs = Input(shape=input_shape) age_branch = self.build_age_branch(inputs) race_branch = self.build_race_branch(inputs, num_races) gender_branch = self.build_gender_branch(inputs) model = Model(inputs=inputs, outputs = [age_branch, race_branch, gender_branch], name=&quot;face_net&quot;) return model model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict[&#39;race_alias&#39;])) Let’s give a look into our model structure, to have a better understanding of what we are building. We can see from it that we have a single input, that in our case is the image we are feeding the CNN, which does decompose into three separated branches, each with their own Convolutions, followed by their respective Dense layers. Training our model Now it’s time to train our multi-output model, once we have both the data ready to use and the model architecture defined. But before doing this step, we need to compile our model. For this task, we will use a learning rate of 0.0004 and an Adam optimizer, but you can be feel free to try with other hyperparameters. We will also use custom loss weights and a custom loss function for each feature. When building our optimizer, let’s use a decay based on the learning rate divided by the number of epochs, so we will slowly be decreasing our learning rate over the epochs. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from keras.optimizers import Adam init_lr = 1e-4 epochs = 100 opt = Adam(lr=init_lr, decay=init_lr / epochs) model.compile(optimizer=opt, loss={ &#39;age_output&#39;: &#39;mse&#39;, &#39;race_output&#39;: &#39;categorical_crossentropy&#39;, &#39;gender_output&#39;: &#39;binary_crossentropy&#39;}, loss_weights={ &#39;age_output&#39;: 4., &#39;race_output&#39;: 1.5, &#39;gender_output&#39;: 0.1}, metrics={ &#39;age_output&#39;: &#39;mae&#39;, &#39;race_output&#39;: &#39;accuracy&#39;, &#39;gender_output&#39;: &#39;accuracy&#39;}) Now let’s train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from keras.callbacks import ModelCheckpoint batch_size = 32 valid_batch_size = 32 train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size) valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size) callbacks = [ ModelCheckpoint(&quot;./model_checkpoint&quot;, monitor=&#39;val_loss&#39;) ] history = model.fit_generator(train_gen, steps_per_epoch=len(train_idx)//batch_size, epochs=epochs, callbacks=callbacks, validation_data=valid_gen, validation_steps=len(valid_idx)//valid_batch_size) Once we have our model trained, let’s give a better look into how our model performed on both training and validation sets over the epochs: Race accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;race_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_race_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for race feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() We can see that by epoch 50 our model stabilizes itself on the validation set, only increasing on the training one, with an accuracy of approximately 80%. Gender accuracy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 plt.clf() fig = go.Figure() fig.add_trace(go.Scatter( y=history.history[&#39;gender_output_acc&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scatter( y=history.history[&#39;val_gender_output_acc&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Accuracy for gender feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Accuracy&#39;) fig.show() Similarly to the race feature, we can see that our model is able to learn most of the patterns to properly predict the gender from a given individual by the 30th epoch, with an accuracy of approximately 90%. Age Mean Absolute Error 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 plt.clf() fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;age_output_mean_absolute_error&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_age_output_mean_absolute_error&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Mean Absolute Error for age feature&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Mean Absolute Error&#39;) fig.show() In the task of predicting the age feature, we can see that our model takes around 60 epochs to properly stabilize its learning process, with a mean absolute error of 0.09. Overall loss 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fig = go.Figure() fig.add_trace(go.Scattergl( y=history.history[&#39;loss&#39;], name=&#39;Train&#39;)) fig.add_trace(go.Scattergl( y=history.history[&#39;val_loss&#39;], name=&#39;Valid&#39;)) fig.update_layout(height=500, width=700, title=&#39;Overall loss&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Loss&#39;) fig.show() We can notice that by the epoch 50 our model starts to stabilize with a loss value of approximately 1.4. There is also a peak in the loss curve which does appear in the Mean Absolute Error for the age feature, which could explain the influence on the learning of the age feature on the overall loss. Evaluating our model on the test set In order to assess how our model performs on the test set, let’s use our UTK data generator class, but this time using the test indexes. We will then call the predict_generator method from our trained model, which will output our the predictions for the test set. 1 2 3 4 test_batch_size = 128 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) age_pred, race_pred, gender_pred = model.predict_generator(test_generator, steps=len(test_idx)//test_batch_size) Let’s iterate one more time over all our test samples, in order to have their labels into a single list. We will also extract the arg max of each record, in order to retrieve the top predictions and ground truths. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size) samples = 0 images, age_true, race_true, gender_true = [], [], [], [] for test_batch in test_generator: image = test_batch[0] labels = test_batch[1] images.extend(image) age_true.extend(labels[0]) race_true.extend(labels[1]) gender_true.extend(labels[2]) age_true = np.array(age_true) race_true = np.array(race_true) gender_true = np.array(gender_true) race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1) race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1) age_true = age_true * data_generator.max_age age_pred = age_pred * data_generator.max_age And finally, let’s print the classification reports for each feature on the test set. 1 2 3 4 from sklearn.metrics import classification_report cr_race = classification_report(race_true, race_pred, target_names=dataset_dict[&#39;race_alias&#39;].keys()) print(cr_race) 1 2 3 4 5 6 7 8 9 10 11 precision recall f1-score support white 0.80 0.91 0.85 2994 black 0.86 0.82 0.84 1327 asian 0.86 0.79 0.83 1046 indian 0.74 0.74 0.74 1171 others 0.38 0.19 0.25 502 accuracy 0.80 7040 macro avg 0.73 0.69 0.70 7040 weighted avg 0.78 0.80 0.78 7040 From the report above, we can see that our model is really good at predicting asian and black individuals, with a precision of 0.86, followed by white people with 0.80 and indian with 0.74. The race ‘others’ shows a precision of only 0.38, but we need to take into consideration that this group is composed of different races and ethnicities along with a small number of samples, when compared to the other groups. The weighted accuracy for this classification task is 78%, showing that our classifier was able to properly learn patterns to distinguish different types of races. 1 2 cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict[&#39;gender_alias&#39;].keys()) print(cr_gender) 1 2 3 4 5 6 7 8 precision recall f1-score support male 0.94 0.87 0.91 3735 female 0.87 0.94 0.90 3305 accuracy 0.90 7040 macro avg 0.90 0.91 0.90 7040 weighted avg 0.91 0.90 0.90 7040 From this report, we can notice that our model is really good at predicting the gender of a given individual, with a weighted accuracy of 91% for this task. 1 2 3 from sklearn.metrics import r2_score print(&#39;R2 score for age: &#39;, r2_score(age_true, age_pred)) R2 score for age: 0.5823979466456328 Example of predictions Below we will plot some examples of the performed predictions generated by our model. We can clearly see that our model is really good at predicting gender, race and age, with some minor mistakes for the age feature. References UTK Face Dataset: http://aicip.eecs.utk.edu/wiki/UTKFace Keras Multi-output documentation: https://keras.io/getting-started/functional-api-guide/ SanjayaSubedi post on multi-output model: https://sanjayasubedi.com.np/deeplearning/multioutput-keras/ PyImageSearch post on FashionNet: https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/ Plotly: https://plot.ly/","headline":"Building a multi-output Convolutional Neural Network with Keras","image":"https://bressan.xyz/assets/img/posts/04-multi-output/banner.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"https://bressan.xyz/posts/keras-multi-output/"},"url":"https://bressan.xyz/posts/keras-multi-output/"}</script><title>Building a multi-output Convolutional Neural Network with Keras | Rodrigo Bressan</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Rodrigo Bressan"><meta name="application-name" content="Rodrigo Bressan"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"> <img src="/assets/img/me.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"> </a><h1 class="site-title"> <a href="/">Rodrigo Bressan</a></h1><p class="site-subtitle fst-italic mb-0">Software, Healthcare and Improving People's lives</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/contact/" class="nav-link"> <i class="fa-fw fas fa-address-card"></i> <span>CONTACT</span> </a><li class="nav-item"> <a href="/projects/" class="nav-link"> <i class="fa-fw fas fa-code"></i> <span>PROJECTS</span> </a><li class="nav-item"> <a href="/resume/" class="nav-link"> <i class="fa-fw fas fa-file"></i> <span>RESUME</span> </a><li class="nav-item"> <a href="/all-posts/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ALL POSTS</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <a href="https://github.com/rodrigobressan" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://www.linkedin.com/in/rbressan/" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Building a multi-output Convolutional Neural Network with Keras</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4" ><article class="px-1"><header><h1 data-toc-skip>Building a multi-output Convolutional Neural Network with Keras</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1647352800" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Mar 15, 2022 </time> </span><div class="mt-3 mb-3"> <a href="/assets/img/posts/04-multi-output/banner.jpeg" class="popup img-link preview-img shimmer"><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1200 630'%3E%3C/svg%3E" data-src="/assets/img/posts/04-multi-output/banner.jpeg" alt="Preview Image" width="1200" height="630" class="lazyload" data-proofer-ignore></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/rodrigobressan">Rodrigo Bressan</a> </em> </span> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="3204 words" > <em>17 min</em> read</span></div></div></header><div class="content"><p>In this post, we will be exploring the Keras functional API in order to build a multi-output Deep Learning model. We will show how to train a single model that is capable of predicting three distinct outputs. By using the UTK Face dataset, which is composed of over 20 thousand pictures of people in uncontrolled environments, we will predict the age, gender and sex for each record presented in the dataset, reaching an accuracy of 91% for gender and 78% for race.</p><h3 id="the-dataset"><span class="me-2">The dataset</span><a href="#the-dataset" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div style="width: 100%; text-align: center"> <a href="/assets/img/posts/04-multi-output/utk_dataset.jpg" class="popup img-link "><img style="width: 80%; object-fit: contain" data-src="/assets/img/posts/04-multi-output/utk_dataset.jpg" class="lazyload" data-proofer-ignore></a></div><p><br /></p><p>The UTKFace dataset is a large dataset composed of over 20 thousand face images with their respectivce annotations of age, gender and ethnicity. The images are properly cropped into the face region, but display some variations in pose, illumination, resolution, etc.</p><p>In order to retrieve the annotations of each record, we need to parse the filenames. Each record is stored in the following format: <strong>age_gender_race_date&amp;time.jpg</strong></p><p>Where:</p><ul><li>age is an integer from 0 to 116<li>gender is an integer in which 0 represents male and 1 represents female<li>race is an integer from 0 to 4, denoting white, black, asian, indian and others, respectively<li>date and time, denoting when the picture was taken</ul><p>If you want to know more about this dataset, please check their <a href="http://aicip.eecs.utk.edu/wiki/UTKFace">website</a>.</p><p>Let’s start by importing some libraries and creating our dictionary to help us on parsing the information from the dataset, along with some other information (dataset location, training split, width and height of the samples).</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">dataset_folder_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">UTKFace</span><span class="sh">'</span>

<span class="n">TRAIN_TEST_SPLIT</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">IM_WIDTH</span> <span class="o">=</span> <span class="n">IM_HEIGHT</span> <span class="o">=</span> <span class="mi">198</span>

<span class="n">dataset_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
        <span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">,</span> 
        <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> 
        <span class="mi">2</span><span class="p">:</span> <span class="sh">'</span><span class="s">asian</span><span class="sh">'</span><span class="p">,</span> 
        <span class="mi">3</span><span class="p">:</span> <span class="sh">'</span><span class="s">indian</span><span class="sh">'</span><span class="p">,</span> 
        <span class="mi">4</span><span class="p">:</span> <span class="sh">'</span><span class="s">others</span><span class="sh">'</span>
    <span class="p">},</span>
    <span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
        <span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">male</span><span class="sh">'</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">female</span><span class="sh">'</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_alias</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">((</span><span class="n">g</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">].</span><span class="nf">items</span><span class="p">())</span>
<span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_alias</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">((</span><span class="n">r</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">].</span><span class="nf">items</span><span class="p">())</span>
</pre></table></code></div></div><p><br /></p><p>Let’s also define a function to help us on extracting the data from our dataset. This function will be used to iterate over each file of the UTK dataset and return a Pandas Dataframe containing all the fields (age, gender and sex) of our records.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">parse_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">ext</span><span class="o">=</span><span class="sh">'</span><span class="s">jpg</span><span class="sh">'</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with
    the data (age, gender and sex) of all files.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">parse_info_from_file</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Parse information from a single file
        </span><span class="sh">"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">path</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">age</span><span class="p">,</span> <span class="n">gender</span><span class="p">,</span> <span class="n">race</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">filename</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)</span>

            <span class="k">return</span> <span class="nf">int</span><span class="p">(</span><span class="n">age</span><span class="p">),</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">][</span><span class="nf">int</span><span class="p">(</span><span class="n">gender</span><span class="p">)],</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">][</span><span class="nf">int</span><span class="p">(</span><span class="n">race</span><span class="p">)]</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
        
    <span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="nf">glob</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">*.%s</span><span class="sh">"</span> <span class="o">%</span> <span class="n">ext</span><span class="p">))</span>
    
    <span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
        <span class="n">info</span> <span class="o">=</span> <span class="nf">parse_info_from_file</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
        <span class="n">records</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>
        
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">records</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">file</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">files</span>
    <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">gender</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">race</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">file</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">df</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">df</span> <span class="o">=</span> <span class="nf">parse_dataset</span><span class="p">(</span><span class="n">dataset_folder_name</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</pre></table></code></div></div><div class="table-wrapper"><table><thead><tr><th style="text-align: right"> <th style="text-align: right">age<th style="text-align: left">gender<th style="text-align: left">race<th style="text-align: left">file<tbody><tr><td style="text-align: right">0<td style="text-align: right">30<td style="text-align: left">male<td style="text-align: left">asian<td style="text-align: left">UTKFace/30_0_2_20170119183959989.jpg.chip.jpg<tr><td style="text-align: right">1<td style="text-align: right">13<td style="text-align: left">female<td style="text-align: left">others<td style="text-align: left">UTKFace/13_1_4_20170103200733438.jpg.chip.jpg<tr><td style="text-align: right">2<td style="text-align: right">36<td style="text-align: left">male<td style="text-align: left">white<td style="text-align: left">UTKFace/36_0_0_20170104204301875.jpg.chip.jpg<tr><td style="text-align: right">3<td style="text-align: right">72<td style="text-align: left">male<td style="text-align: left">black<td style="text-align: left">UTKFace/72_0_1_20170116205624331.jpg.chip.jpg<tr><td style="text-align: right">4<td style="text-align: right">35<td style="text-align: left">female<td style="text-align: left">white<td style="text-align: left">UTKFace/35_1_0_20170116201535811.jpg.chip.jpg<tr><td style="text-align: right">5<td style="text-align: right">80<td style="text-align: left">female<td style="text-align: left">white<td style="text-align: left">UTKFace/80_1_0_20170110182107291.jpg.chip.jpg<tr><td style="text-align: right">6<td style="text-align: right">1<td style="text-align: left">male<td style="text-align: left">asian<td style="text-align: left">UTKFace/1_0_2_20161219203236876.jpg.chip.jpg<tr><td style="text-align: right">7<td style="text-align: right">25<td style="text-align: left">female<td style="text-align: left">indian<td style="text-align: left">UTKFace/25_1_3_20170119171956657.jpg.chip.jpg<tr><td style="text-align: right">8<td style="text-align: right">61<td style="text-align: left">male<td style="text-align: left">indian<td style="text-align: left">UTKFace/61_0_3_20170109141653583.jpg.chip.jpg<tr><td style="text-align: right">9<td style="text-align: right">32<td style="text-align: left">male<td style="text-align: left">indian<td style="text-align: left">UTKFace/32_0_3_20170119200339548.jpg.chip.jpg</table></div><p><br /></p><h3 id="data-visualization"><span class="me-2">Data visualization</span><a href="#data-visualization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>As an important step to understand not only the distribution of our dataset, but as well the predictions generated by our model, we need to perform some data visualization process on our dataset.</p><p>We will start by defining a helper function to generate pie plots based on a given Pandas series:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="k">def</span> <span class="nf">plot_distribution</span><span class="p">(</span><span class="n">pd_series</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">pd_series</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">().</span><span class="n">index</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">pd_series</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">().</span><span class="n">values</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
    
    <span class="n">pie_plot</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Pie</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">counts</span><span class="p">,</span> <span class="n">hole</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">pie_plot</span><span class="p">])</span>
    <span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">title_text</span><span class="o">=</span><span class="sh">'</span><span class="s">Distribution for %s</span><span class="sh">'</span> <span class="o">%</span> <span class="n">pd_series</span><span class="p">.</span><span class="n">name</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p><br /></p><h4 id="race-distribution"><span class="me-2">Race distribution</span><a href="#race-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Let’s start by plotting the race distribution with our predefined plot_distribution method.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nf">plot_distribution</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">race</span><span class="sh">'</span><span class="p">])</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/pie_race.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>Having a quick glance at this plot, we can see that almost half of the samples are from the white race, so we can expect this group to have a great accuracy. Other races such as black, indian and asian also show a good number of samples, probably leading us to good accuracy numbers as well. The race ‘others’ (hispanics, latinos, etc) on the other side, show a small number of samples, being more likely to have a small accuracy.</p><p><br /></p><h4 id="gender-distribution"><span class="me-2">Gender distribution</span><a href="#gender-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nf">plot_distribution</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">gender</span><span class="sh">'</span><span class="p">])</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/pie_gender.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>For both male and female samples, we have quite a good balanced number of records, so we should have a great accuracy for both classes when using our model.</p><p><br /></p><h4 id="age-distribution"><span class="me-2">Age distribution</span><a href="#age-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Let’s also plot how our age feature is distributed over the dataset by using a simple histogram with 20 bins.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">age</span><span class="sh">"</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">title_text</span><span class="o">=</span><span class="sh">'</span><span class="s">Age distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/hist_age.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>We can also display this same plot in a pie plot. Let’s group the age column into bins and then plot it with a pie chart</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">&lt;10</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">10-20</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">20-30</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">30-40</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">40-60</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">60-80</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">80+</span><span class="sh">'</span><span class="p">]</span>

<span class="n">age_binned</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
<span class="nf">plot_distribution</span><span class="p">(</span><span class="n">age_binned</span><span class="p">)</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/pie_age.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>We can observe that our dataset is mostly composed of individuals which age varies between 20 and 30 years, followed by individuals ranging from 30-40 years and then 40-60 years old. These groups represent around 70% of our dataset, so we can believe that we are going to have a good accuracy on predicting individuals in these ranges.</p><p>We could also perform some multi-variate analysis on our dataset, but since the scope of this notebook is to demonstrate the usage of a multi-output model with Keras, we won’t be covering it.</p><p><br /></p><h3 id="data-generator"><span class="me-2">Data generator</span><a href="#data-generator" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>In order to input our data to our Keras multi-output model, we will create a helper object to work as a data generator for our dataset. This will be done by generating batches of data, which will be used to feed our multi-output model with both the images and their labels. This step is also done instead of just loading all the dataset into the memory at once, which could lead to an out of memory error.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="k">class</span> <span class="nc">UtkFaceDataGenerator</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">
    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
        
    <span class="k">def</span> <span class="nf">generate_split_indexes</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">))</span>
        <span class="n">train_up_to</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="n">TRAIN_TEST_SPLIT</span><span class="p">)</span>
        <span class="n">train_idx</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:</span><span class="n">train_up_to</span><span class="p">]</span>
        <span class="n">test_idx</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">train_up_to</span><span class="p">:]</span>

        <span class="n">train_up_to</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">train_up_to</span> <span class="o">*</span> <span class="n">TRAIN_TEST_SPLIT</span><span class="p">)</span>
        <span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">train_idx</span><span class="p">[:</span><span class="n">train_up_to</span><span class="p">],</span> <span class="n">train_idx</span><span class="p">[</span><span class="n">train_up_to</span><span class="p">:]</span>
        
        <span class="c1"># converts alias to id
</span>        <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">gender</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">gender</span><span class="p">:</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_alias</span><span class="sh">'</span><span class="p">][</span><span class="n">gender</span><span class="p">])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">race</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">race</span><span class="p">:</span> <span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_alias</span><span class="sh">'</span><span class="p">][</span><span class="n">race</span><span class="p">])</span>

        <span class="n">self</span><span class="p">.</span><span class="n">max_age</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">,</span> <span class="n">test_idx</span>
    
    <span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">img_path</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to perform some minor preprocessing on the image before inputting into the network.
        </span><span class="sh">"""</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="nf">resize</span><span class="p">((</span><span class="n">IM_WIDTH</span><span class="p">,</span> <span class="n">IM_HEIGHT</span><span class="p">))</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">im</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
        
        <span class="k">return</span> <span class="n">im</span>
        
    <span class="k">def</span> <span class="nf">generate_images</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image_idx</span><span class="p">,</span> <span class="n">is_training</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to generate a batch with images when training/testing/validating our Keras model.
        </span><span class="sh">"""</span>
        
        <span class="c1"># arrays to store our batched data
</span>        <span class="n">images</span><span class="p">,</span> <span class="n">ages</span><span class="p">,</span> <span class="n">races</span><span class="p">,</span> <span class="n">genders</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">image_idx</span><span class="p">:</span>
                <span class="n">person</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                
                <span class="n">age</span> <span class="o">=</span> <span class="n">person</span><span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">]</span>
                <span class="n">race</span> <span class="o">=</span> <span class="n">person</span><span class="p">[</span><span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">]</span>
                <span class="n">gender</span> <span class="o">=</span> <span class="n">person</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">]</span>
                <span class="nb">file</span> <span class="o">=</span> <span class="n">person</span><span class="p">[</span><span class="sh">'</span><span class="s">file</span><span class="sh">'</span><span class="p">]</span>
                
                <span class="n">im</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">preprocess_image</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
                
                <span class="n">ages</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">age</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">max_age</span><span class="p">)</span>
                <span class="n">races</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">race</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_id</span><span class="sh">'</span><span class="p">])))</span>
                <span class="n">genders</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">to_categorical</span><span class="p">(</span><span class="n">gender</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_id</span><span class="sh">'</span><span class="p">])))</span>
                <span class="n">images</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
                
                <span class="c1"># yielding condition
</span>                <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">batch_size</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">ages</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">races</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">genders</span><span class="p">)]</span>
                    <span class="n">images</span><span class="p">,</span> <span class="n">ages</span><span class="p">,</span> <span class="n">races</span><span class="p">,</span> <span class="n">genders</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
                    
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_training</span><span class="p">:</span>
                <span class="k">break</span>
                
<span class="n">data_generator</span> <span class="o">=</span> <span class="nc">UtkFaceDataGenerator</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="nf">generate_split_indexes</span><span class="p">()</span>
</pre></table></code></div></div><p><br /></p><h3 id="building-our-model"><span class="me-2">Building our model</span><a href="#building-our-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>In this step, we will define our multi-output Keras model. Our model will be composed of three major branches, one for each available feature: age, gender and race.</p><p>The default structure for our convolutional layers is based on a Conv2D layer with a ReLU activation, followed by a BatchNormalization layer, a MaxPooling and then finally a Dropout layer. Each of these layers is then followed by the final Dense layer. This step is repeated for each of the outputs we are trying to predict.</p><p>These default layers are defined on the make_default_hidden_layers method, which will be reused on building each of the branches of our model. In the code below we will define our class that will be responsible for creating our multi-output model.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="n">keras.layers.normalization</span> <span class="kn">import</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="n">keras.layers.convolutional</span> <span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span> <span class="n">keras.layers.convolutional</span> <span class="kn">import</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="n">keras.layers.core</span> <span class="kn">import</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="n">keras.layers.core</span> <span class="kn">import</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="n">keras.layers.core</span> <span class="kn">import</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="n">keras.layers.core</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="k">class</span> <span class="nc">UtkMultiOutputModel</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">
    Used to generate our multi-output model. This CNN contains three branches, one for age, other for 
    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined
    on the make_default_hidden_layers method.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">make_default_hidden_layers</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to generate a default set of hidden layers. The structure used in this network is defined as:
        
        Conv2D -&gt; BatchNormalization -&gt; Pooling -&gt; Dropout
        </span><span class="sh">"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">build_race_branch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">num_races</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to build the race branch of our face recognition network.
        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, 
        followed by the Dense output layer.
        </span><span class="sh">"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_default_hidden_layers</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">num_races</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">softmax</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">race_output</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">build_gender_branch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">num_genders</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to build the gender branch of our face recognition network.
        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, 
        followed by the Dense output layer.
        </span><span class="sh">"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="nf">rgb_to_grayscale</span><span class="p">(</span><span class="n">c</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_default_hidden_layers</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">num_genders</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">gender_output</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">build_age_branch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>   
        <span class="sh">"""</span><span class="s">
        Used to build the age branch of our face recognition network.
        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, 
        followed by the Dense output layer.

        </span><span class="sh">"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">make_default_hidden_layers</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">age_output</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">assemble_full_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">num_races</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Used to assemble our multi-output model CNN.
        </span><span class="sh">"""</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>

        <span class="n">age_branch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">build_age_branch</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">race_branch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">build_race_branch</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_races</span><span class="p">)</span>
        <span class="n">gender_branch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">build_gender_branch</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                     <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">age_branch</span><span class="p">,</span> <span class="n">race_branch</span><span class="p">,</span> <span class="n">gender_branch</span><span class="p">],</span>
                     <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">face_net</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="nc">UtkMultiOutputModel</span><span class="p">().</span><span class="nf">assemble_full_model</span><span class="p">(</span><span class="n">IM_WIDTH</span><span class="p">,</span> <span class="n">IM_HEIGHT</span><span class="p">,</span> <span class="n">num_races</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_alias</span><span class="sh">'</span><span class="p">]))</span>
</pre></table></code></div></div><p><br /></p><p>Let’s give a look into our model structure, to have a better understanding of what we are building. We can see from it that we have a single input, that in our case is the image we are feeding the CNN, which does decompose into three separated branches, each with their own Convolutions, followed by their respective Dense layers.</p><p><br /></p><div style="width: 100%; text-align: center"> <a href="/assets/img/posts/04-multi-output/model.png" class="popup img-link "><img style="width: 100%; object-fit: contain" data-src="/assets/img/posts/04-multi-output/model.png" class="lazyload" data-proofer-ignore></a></div><p><br /></p><h3 id="training-our-model"><span class="me-2">Training our model</span><a href="#training-our-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Now it’s time to train our multi-output model, once we have both the data ready to use and the model architecture defined. But before doing this step, we need to compile our model. For this task, we will use a learning rate of 0.0004 and an Adam optimizer, but you can be feel free to try with other hyperparameters. We will also use custom loss weights and a custom loss function for each feature.</p><p>When building our optimizer, let’s use a decay based on the learning rate divided by the number of epochs, so we will slowly be decreasing our learning rate over the epochs.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">init_lr</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">opt</span> <span class="o">=</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">init_lr</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="n">init_lr</span> <span class="o">/</span> <span class="n">epochs</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="p">{</span>
                  <span class="sh">'</span><span class="s">age_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">,</span> 
                  <span class="sh">'</span><span class="s">race_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> 
                  <span class="sh">'</span><span class="s">gender_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">binary_crossentropy</span><span class="sh">'</span><span class="p">},</span>
              <span class="n">loss_weights</span><span class="o">=</span><span class="p">{</span>
                  <span class="sh">'</span><span class="s">age_output</span><span class="sh">'</span><span class="p">:</span> <span class="mf">4.</span><span class="p">,</span> 
                  <span class="sh">'</span><span class="s">race_output</span><span class="sh">'</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">,</span> 
                  <span class="sh">'</span><span class="s">gender_output</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">{</span>
                  <span class="sh">'</span><span class="s">age_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">mae</span><span class="sh">'</span><span class="p">,</span> 
                  <span class="sh">'</span><span class="s">race_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span>
                  <span class="sh">'</span><span class="s">gender_output</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">})</span>
</pre></table></code></div></div><p><br /></p><p>Now let’s train our model with a batch size of 32 for both valid and train sets. We will be using a ModelCheckpoint callback in order to save the model on disk at the end of each epoch.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">valid_batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_gen</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="nf">generate_images</span><span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">valid_gen</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="nf">generate_images</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">valid_batch_size</span><span class="p">)</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="sh">"</span><span class="s">./model_checkpoint</span><span class="sh">"</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit_generator</span><span class="p">(</span><span class="n">train_gen</span><span class="p">,</span>
                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_gen</span><span class="p">,</span>
                    <span class="n">validation_steps</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span><span class="o">//</span><span class="n">valid_batch_size</span><span class="p">)</span>
</pre></table></code></div></div><p>Once we have our model trained, let’s give a better look into how our model performed on both training and validation sets over the epochs:</p><p><br /></p><h4 id="race-accuracy"><span class="me-2">Race accuracy</span><a href="#race-accuracy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">race_output_acc</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_race_output_acc</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Valid</span><span class="sh">'</span><span class="p">))</span>


<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                  <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Accuracy for race feature</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">xaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">yaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/acc_race.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>We can see that by epoch 50 our model stabilizes itself on the validation set, only increasing on the training one, with an accuracy of approximately 80%.</p><p><br /></p><h4 id="gender-accuracy"><span class="me-2">Gender accuracy</span><a href="#gender-accuracy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_output_acc</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_gender_output_acc</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Valid</span><span class="sh">'</span><span class="p">))</span>


<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                  <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Accuracy for gender feature</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">xaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">yaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">)</span>


<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/acc_gender.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>Similarly to the race feature, we can see that our model is able to learn most of the patterns to properly predict the gender from a given individual by the 30th epoch, with an accuracy of approximately 90%.</p><p><br /></p><h4 id="age-mean-absolute-error"><span class="me-2">Age Mean Absolute Error</span><a href="#age-mean-absolute-error" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="nf">clf</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scattergl</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">age_output_mean_absolute_error</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scattergl</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_age_output_mean_absolute_error</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Valid</span><span class="sh">'</span><span class="p">))</span>


<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                  <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Mean Absolute Error for age feature</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">xaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">yaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Mean Absolute Error</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/mae_age.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>In the task of predicting the age feature, we can see that our model takes around 60 epochs to properly stabilize its learning process, with a mean absolute error of 0.09. <br /></p><h4 id="overall-loss"><span class="me-2">Overall loss</span><a href="#overall-loss" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scattergl</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Train</span><span class="sh">'</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scattergl</span><span class="p">(</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Valid</span><span class="sh">'</span><span class="p">))</span>


<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                  <span class="n">width</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="sh">'</span><span class="s">Overall loss</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">xaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">yaxis_title</span><span class="o">=</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><iframe src="/assets/plots/04-multi-output/overall_loss.html" id="igraph" scrolling="no" style="border:none;" seamless="seamless" height="500" width="100%" loading="lazy"></iframe><p>We can notice that by the epoch 50 our model starts to stabilize with a loss value of approximately 1.4. There is also a peak in the loss curve which does appear in the Mean Absolute Error for the age feature, which could explain the influence on the learning of the age feature on the overall loss.</p><p><br /></p><h3 id="evaluating-our-model-on-the-test-set"><span class="me-2">Evaluating our model on the test set</span><a href="#evaluating-our-model-on-the-test-set" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>In order to assess how our model performs on the test set, let’s use our UTK data generator class, but this time using the test indexes. We will then call the predict_generator method from our trained model, which will output our the predictions for the test set.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">test_generator</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="nf">generate_images</span><span class="p">(</span><span class="n">test_idx</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">)</span>
<span class="n">age_pred</span><span class="p">,</span> <span class="n">race_pred</span><span class="p">,</span> <span class="n">gender_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_generator</span><span class="p">,</span> 
                                                           <span class="n">steps</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">test_idx</span><span class="p">)</span><span class="o">//</span><span class="n">test_batch_size</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><p>Let’s iterate one more time over all our test samples, in order to have their labels into a single list. We will also extract the arg max of each record, in order to retrieve the top predictions and ground truths.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="n">test_generator</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="nf">generate_images</span><span class="p">(</span><span class="n">test_idx</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">images</span><span class="p">,</span> <span class="n">age_true</span><span class="p">,</span> <span class="n">race_true</span><span class="p">,</span> <span class="n">gender_true</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">test_batch</span> <span class="ow">in</span> <span class="n">test_generator</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">images</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">age_true</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">race_true</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">gender_true</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    
<span class="n">age_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">age_true</span><span class="p">)</span>
<span class="n">race_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">race_true</span><span class="p">)</span>
<span class="n">gender_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">gender_true</span><span class="p">)</span>

<span class="n">race_true</span><span class="p">,</span> <span class="n">gender_true</span> <span class="o">=</span> <span class="n">race_true</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">gender_true</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">race_pred</span><span class="p">,</span> <span class="n">gender_pred</span> <span class="o">=</span> <span class="n">race_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">gender_pred</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">age_true</span> <span class="o">=</span> <span class="n">age_true</span> <span class="o">*</span> <span class="n">data_generator</span><span class="p">.</span><span class="n">max_age</span>
<span class="n">age_pred</span> <span class="o">=</span> <span class="n">age_pred</span> <span class="o">*</span> <span class="n">data_generator</span><span class="p">.</span><span class="n">max_age</span>
</pre></table></code></div></div><p><br /></p><p>And finally, let’s print the classification reports for each feature on the test set.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">cr_race</span> <span class="o">=</span> <span class="nf">classification_report</span><span class="p">(</span><span class="n">race_true</span><span class="p">,</span> <span class="n">race_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">race_alias</span><span class="sh">'</span><span class="p">].</span><span class="nf">keys</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cr_race</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>              precision    recall  f1-score   support

       white       0.80      0.91      0.85      2994
       black       0.86      0.82      0.84      1327
       asian       0.86      0.79      0.83      1046
      indian       0.74      0.74      0.74      1171
      others       0.38      0.19      0.25       502

    accuracy                           0.80      7040
   macro avg       0.73      0.69      0.70      7040
weighted avg       0.78      0.80      0.78      7040
</pre></table></code></div></div><p><br /></p><p>From the report above, we can see that our model is really good at predicting asian and black individuals, with a precision of 0.86, followed by white people with 0.80 and indian with 0.74. The race ‘others’ shows a precision of only 0.38, but we need to take into consideration that this group is composed of different races and ethnicities along with a small number of samples, when compared to the other groups. The weighted accuracy for this classification task is 78%, showing that our classifier was able to properly learn patterns to distinguish different types of races.</p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">cr_gender</span> <span class="o">=</span> <span class="nf">classification_report</span><span class="p">(</span><span class="n">gender_true</span><span class="p">,</span> <span class="n">gender_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">dataset_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">gender_alias</span><span class="sh">'</span><span class="p">].</span><span class="nf">keys</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="n">cr_gender</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>              precision    recall  f1-score   support

        male       0.94      0.87      0.91      3735
      female       0.87      0.94      0.90      3305

    accuracy                           0.90      7040
   macro avg       0.90      0.91      0.90      7040
weighted avg       0.91      0.90      0.90      7040
</pre></table></code></div></div><p><br /> From this report, we can notice that our model is really good at predicting the gender of a given individual, with a weighted accuracy of 91% for this task.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed=""><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">R2 score for age: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">age_true</span><span class="p">,</span> <span class="n">age_pred</span><span class="p">))</span>
</pre></table></code></div></div><p>R2 score for age: 0.5823979466456328</p><p><br /></p><h4 id="example-of-predictions"><span class="me-2">Example of predictions</span><a href="#example-of-predictions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Below we will plot some examples of the performed predictions generated by our model. We can clearly see that our model is really good at predicting gender, race and age, with some minor mistakes for the age feature.</p><div style="width: 100%; text-align: center"> <a href="/assets/img/posts/04-multi-output/preds.png" class="popup img-link "><img style="width: 100%; object-fit: contain" data-src="/assets/img/posts/04-multi-output/preds.png" class="lazyload" data-proofer-ignore></a></div><p><br /></p><h2 id="references"><span class="me-2">References</span><a href="#references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>UTK Face Dataset: <a href="http://aicip.eecs.utk.edu/wiki/UTKFace">http://aicip.eecs.utk.edu/wiki/UTKFace</a></p><p>Keras Multi-output documentation: <a href="https://keras.io/getting-started/functional-api-guide/">https://keras.io/getting-started/functional-api-guide/</a></p><p>SanjayaSubedi post on multi-output model: <a href="https://sanjayasubedi.com.np/deeplearning/multioutput-keras/">https://sanjayasubedi.com.np/deeplearning/multioutput-keras/</a></p><p>PyImageSearch post on FashionNet: <a href="https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/">https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/</a></p><p>Plotly: <a href="https://plot.ly/">https://plot.ly/</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/data-science/">data science</a>, <a href="/categories/machine-learning/">machine learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/data-science/" class="post-tag no-text-decoration" >data science</a> <a href="/tags/feature-engineering/" class="post-tag no-text-decoration" >feature engineering</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine learning</a> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a> <a href="/tags/pandas/" class="post-tag no-text-decoration" >pandas</a> <a href="/tags/scikit-learn/" class="post-tag no-text-decoration" >scikit-learn</a> <a href="/tags/tensorflow/" class="post-tag no-text-decoration" >tensorflow</a> <a href="/tags/keras/" class="post-tag no-text-decoration" >keras</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted me-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Building%20a%20multi-output%20Convolutional%20Neural%20Network%20with%20Keras%20-%20Rodrigo%20Bressan&url=https%3A%2F%2Fbressan.xyz%2Fposts%2Fkeras-multi-output%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter" > <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Building%20a%20multi-output%20Convolutional%20Neural%20Network%20with%20Keras%20-%20Rodrigo%20Bressan&u=https%3A%2F%2Fbressan.xyz%2Fposts%2Fkeras-multi-output%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook" > <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fbressan.xyz%2Fposts%2Fkeras-multi-output%2F&text=Building%20a%20multi-output%20Convolutional%20Neural%20Network%20with%20Keras%20-%20Rodrigo%20Bressan" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram" > <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fbressan.xyz%2Fposts%2Fkeras-multi-output%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin" > <i class="fa-fw fab fa-linkedin"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/lynis-audit/">Navigating HIPAA compliance on the Cloud with Lynis</a><li class="text-truncate lh-lg"> <a href="/posts/kopf-k8s-operator/">Simplifying Kubernetes Operators with Kopf: A Quick Guide</a><li class="text-truncate lh-lg"> <a href="/posts/k8s-commands/">Essential kubectl Commands</a><li class="text-truncate lh-lg"> <a href="/posts/nlp-basics/">NLP with Python: A Beginner's Guide</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/data-science/">data science</a> <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a> <a class="post-tag btn btn-outline-primary" href="/tags/cloud/">cloud</a> <a class="post-tag btn btn-outline-primary" href="/tags/feature-engineering/">feature engineering</a> <a class="post-tag btn btn-outline-primary" href="/tags/keras/">keras</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">machine learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/pandas/">pandas</a> <a class="post-tag btn btn-outline-primary" href="/tags/scikit-learn/">scikit-learn</a> <a class="post-tag btn btn-outline-primary" href="/tags/tensorflow/">tensorflow</a> <a class="post-tag btn btn-outline-primary" href="/tags/devops/">devops</a></div></section></div><section id="toc-wrapper" class="ps-0 pe-4 mb-5"><h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/entity-embeddings/" class="post-preview card h-100"><div class="card-body"> <time class="small" data-ts="1640008800" data-df="ll" > Dec 20, 2021 </time><h4 class="pt-0 my-2">Enhancing Categorical Features with Entity Embeddings</h4><div class="text-muted small"><p> Let’s talk about selling beers. Let’s suppose you are the owner of a pub, and you would like to predict how many beers your establishment is going to sell on a given day based on two variables: ...</p></div></div></a></article><article class="col"> <a href="/posts/shap/" class="post-preview card h-100"><div class="card-body"> <time class="small" data-ts="1642255200" data-df="ll" > Jan 15, 2022 </time><h4 class="pt-0 my-2">Elucidating Machine Learning models with SHAP values</h4><div class="text-muted small"><p> The problem During data analysis, we may only look at metrics such as accuracy/precision/recall and worry about not overfitting our data. But are those the only ones that matter? When it comes to...</p></div></div></a></article><article class="col"> <a href="/posts/keras-101-boston/" class="post-preview card h-100"><div class="card-body"> <time class="small" data-ts="1644933600" data-df="ll" > Feb 15, 2022 </time><h4 class="pt-0 my-2">Keras 101: A simple Neural Network for House Pricing regression</h4><div class="text-muted small"><p> In this post, we will be covering some basics of data exploration and building a model with Keras in order to help us on predicting the selling price of a given house in the Boston (MA) area. As an...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/keras-101-boston/" class="btn btn-outline-primary" aria-label="Older" ><p>Keras 101: A simple Neural Network for House Pricing regression</p></a> <a href="/posts/lynis-audit/" class="btn btn-outline-primary" aria-label="Newer" ><p>Navigating HIPAA compliance on the Cloud with Lynis</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p> © <time>2025</time> <a href="https://github.com/rodrigobressan">Rodrigo Bressan</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>See something wrong? Want to contribute? <a href="https://github.com/rodrigobressan/rodrigobressan.github.io/tree/master/_posts">Edit this page 📝</href></p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/data-science/">data science</a> <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a> <a class="post-tag btn btn-outline-primary" href="/tags/cloud/">cloud</a> <a class="post-tag btn btn-outline-primary" href="/tags/feature-engineering/">feature engineering</a> <a class="post-tag btn btn-outline-primary" href="/tags/keras/">keras</a> <a class="post-tag btn btn-outline-primary" href="/tags/machine-learning/">machine learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/pandas/">pandas</a> <a class="post-tag btn btn-outline-primary" href="/tags/scikit-learn/">scikit-learn</a> <a class="post-tag btn btn-outline-primary" href="/tags/tensorflow/">tensorflow</a> <a class="post-tag btn btn-outline-primary" href="/tags/devops/">devops</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.9/dayjs.min.js,npm/dayjs@1.11.9/locale/en.min.js,npm/dayjs@1.11.9/plugin/relativeTime.min.js,npm/dayjs@1.11.9/plugin/localizedFormat.min.js,npm/tocbot@4.21.1/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/unregister.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-5B9QC89SHN"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-5B9QC89SHN'); }); </script> <script> /* Note: dependent library will be loaded in `js-selector.html` */ SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5"></p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
